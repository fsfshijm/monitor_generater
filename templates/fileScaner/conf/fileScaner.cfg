[sys]

#日志分布的服务器，逗号分割，通过ssh连接，需要在脚本运行的机器上建立到这些机器的信任
#如果是当前机器，则配置为localhost
#如果下面的type＝1，可以配置为localhost，或者以逗号分割的ip地址；否则只能为localhost，需要把其他机器的文件同步到脚本运行的机器上(目前主要是101)
servers = 192.168.10.20,192.168.10.21

#文件所在目录, 可以用正则
fileDir = /data/search/data/advertise_log/backup 

#文件名，支持正则表达式
#fileScanerTime 会被时间戳替换掉,到小时级
fileRegex = ws.access.log.fileScanerTime*

#-1: 文件不带时间戳
#>=0: 看N小时之前的数据
hoursAgo = 2

#控制是否需要预处理, 为空-不需要预处理，不为空-会根据下面的正则把日志重新过滤重定向到一个新的文件中
PrePrcessRegex = ERROR_CODE

#type: 获取数据的方式
#1: 直接统计文件记录数,可以跨机器,机器ip在上面的servers中配置
#2: 需要根据key过滤统计文件内容，必须把文件同步到一台机器，上面的servers配置为localhost
#3: 扩展的方式, 自己定义
type = 2

##type = 1 时，只计数，如下配置object, 只定义一个object，一个key就行 
#objectList = your_object
#[your_object]
#your_key=任意值，也可以不配置

##type=2 时
objectList = your_obj1,your_obj2

[your_obj1]
your_key1=regex1
your_key2=regex2

[your_obj2]
your_key1=regex1
your_key2=regex2

##type=3时,根据自己的需要修改配置，代码自己实现, 目前已经实现统计日志中一个map数据的功能
##eg. 每条日志都有类似{"reopen_success":1,"config_success":4} 的数据，此处对每一个key进行累加，可以把key拆分到多个object组
#objectList = your_obj1,your_obj2
#[your_obj1]
#keys=your_key1,your_key2
#[your_obj2]
#keys=your_key1,your_key2



[email]
#发报告: 1, 不发: 0
sendEmail=1
server=mail.xxxxxxxx.cn
user=report@xxxxxxxx.cn
password=99b5aa85
fromAddr=report@xxxxxxxx.cn
toAddr=shijingmeng@xxxxxxxx.cn
subject=[QA FileScaner] FileScaner
